# J'IAccuse

## Synopsis

## Scene 1:

Où le procureur présente les faits.
Mrs et Mesdames les jurées, la cours se réunis aujourd'hui pour delibérer sur le conflic qui oppose Mr Alain Michou et L'IA nommée IDx-DR. 
En effet, Mr Michou a déposé une requête en réparation du préjudice subi suite à la perte de la vision. 
Mr Michou a perdu la vue le 13/02/2021 des suites d'une rétinopathie diabétique.
Retinopathie diabetique confirmée par examen de Mr Michou le 12/04/2021 par le professeur Voiclair Ophtalmologue expert auprès des assurances Assuretout.
Diabetique de type 2 depuis une vingtaine d'années, Mr Michou se faisait depister scrupuleusement tous les ans depuis 10 ans par un fond d'oeuil. 
Ayant éprouvé quelques gènes visuels depuis octobre 2020 son opthamologue a réalisé un examen complémentaire en Novembre de la même année.
Les investigations ont montrées que l'ophtamologue de Mr Michou, le docteur Bevu utilisait une camera NFC-B de marque Numalab connectée permettant la prise de vue du fond d'oeuil et transmettait directement le cliché à une inteligence artificiel, nomée Iris+ en charge de la détection d'anomalies. 
Ce principe est recommandé par la FDA aux USA depuis Avril 2018 et approuvé par le conseil de l'ordre des Médecins en france depuis Janv 2019.
A 3 reprises les clichés du fond d'oeuil de Mr Michou n'ont pas inquiété Iris+ et n'ont pas détecté les lésions pourtant avérés sur les fonds d'oeuil de Mr Michou, ceci en particulier sur les examen de Novembre.
En conséquence de quoi Mr Michou demande réparation pour son préjudice 
et le ministère publique souhaite que l'on explique pourquoi L'IA à failli à son devoir de diagnostic.

     

## Scene 2:

Où l'expert présente la technologie mise en cause.
Intel, épistémologue des sciences/historien.ne spécialiste de l'IA et ancien.ne programmeur.meuse d'IA, vous paraissez en qualité d'expert.e cité.e par la cour, pouvez-vous nous donner quelques éléments sur l'Intelligence articielle, alias IA ?
L'expert.e : L'IA c'est le fait de programmer une machine pour lui donner un mode de réflexion le plus semblable au système synaptique humain. La puissance de calcul va être un avantage de plus.
C'est tout d'abord par l'imaginaire de la science fiction, littérature et autres œuvres que notre société a tout d'abord appréhender la problématique. L'un des exemples les plus marquants a été HAL l'ordinateur de bord de 2001 l'Odyssée de l'espace de Stanley Kubrick.

Quand est-on sorti de la science fiction ?
L'expert.e : Cela a commencé à devenir une réalité pour le grand public avec les ordinateurs d'IBM Deep Blue et Deeper Blue qui ont affronté en 1996 et 1997 le champion russe Garry Kasparov. La victoire en 1997 de la machine sur l'homme, pour une partie remportée, la cinquième, est retentissante, même si elle est plus liée à un bug de la machine qu'à un coup de maître. Mais IBM n'a pas laissé ni le champion d'échec ni d'autres informaticiens se pencher sur les logs et autres éléments. Deeper Blue sera même rapidement totalement démonter.
Ce culte du secret tranche avec la stratégie de DeepMind, entreprise britannique rachetée par Google en 2014, qui pour son programme AplhaGo puis AlphaGo Zero, a misé sur des publications dans la revue scientifique internationale Nature, pour valider ses victoires sur les joueurs professionnels de Go, le Français Fan Hui en 2015, publié en janvier 2016, puis le Chinois Ke Jie en mai 2017, avec l'article paru en octobre 2017 qui révèle une architecture simplifiée.
A la veille des années 2020 les voitures connectées constiuaient le symbole de l'IA, avec quelques coups médiatiques de création par des IA, en peinture, en musique, ou pièces de théâtre.
L'intêrêt de l'IA est de faire à la place de l'homme, ou donner lui la bonne orientation, parce que la machine est beaucoup plus régulière et non sensible à un état de forme, en plus d'une capacité de traintement des données qui augmente toujours. Grace au machine learning, l'IA est capable d'améliorer seule son algorithme et donc les solutions qu'elle propose.


## Scene 3:

Où le practicien explique son choix d'utiliser l'IA.

Mesdames, messieurs, je tiens à défendre le cas de l'intelligence artificielle. Non seulement celle-ci est plus efficace en terme de reconnaissance d'elements defectueux chez le patient et a une marge d'erreur inferieure à celle des medecins. Le choix de se fier à son diagnostic n'est pas une erreur, mais je tiens à preciser que le taux d'erreur de l'IA était connue à l'avance de M. Michou et que celui-çi a decidé de lui faire confiance. Cette IA a été developpée dans le but de donner des diagnostics plus précis à des patients et de réduire le nombre d'incidents liés à des mauvais diagnostics. De plus l'IA a été agrémentée par par un organisme d'autorité : le FTA, cela signifie donc que mettre jusqu'à des vies dans les mains de patients a été jugé une bonne solution. Lorsque j'ai proposé la solution de l'IA à M. Michou, je lui ai donné le choix entre son diagnostic, et celui que je pourrai fournir. J'ai suivi la procédure et j'ai expliqué au patient que le diagnostic avait des chances d'être erronné comme si un véritable medecin avait effectué le diagnostic. Les IA ont déja montrés leur capacités dans le passé, notamment dans la copie de comportements humains, que ce soit dans l'apprentissage, ou l'art. Si une IA peut avoir des comportements si humains, elle peut avec aise generer des diagnostics à partir de jeux de données de bonne qualité et de la condition actuelle du patient.

## Scene 4:

Où l'expert nous précise les potentielles erreurs d'une IA.

Avocat practicien : "Vous voyez donc comme tout était mis en place pour laisser penser à mon client que ce programme était infaillible, et pourtant il y a une faille qui a conduit au regrettable incident dont nous débattons aujourd'hui. Voyez les faits votre honneur, le programme n'a pas mené a bien sa mission: il s'est éloigné de son objectif - à savoir: la détection des cas pathologiques - et en ce sens nous pouvons affirmer que le programme a commis une erreur.

Juge: - Votre argument est entendu, mais écoutons d'abord l'avis de notre expert technique.

Expert: - C'est en réalité un problème complexe qui préoccupe le milieu scientifique depuis des décennies. En effet, si nous définissons l'ojectif du programme comme la découverte infaillible des causes provoquant les symptômes observés, il faudrait alors que nous soyons en mesure de fournir au programme les règles exactes qui régissent notre contexte - ici, le corps humain - hors ces règles sont un sujet de recherche constant et par ce fait, une équipe de programmeurs n'auraient pas pu les écrire, puisque n'en ayant pas connaissance. Nous raisonnons donc par induction, c'est-à-dire que nous construisons des théories de plus en plus raffinées en fonction des données que nous avons pu observer.

Avocat Practicien: - Objection votre honneur ! Nous savons d'ores et déjà que la tâche n'aurait pas pu être résolue par une équipe humaine, c'est pourquoi le raisonnement inductif a été relayée a une intelligence artificielle. N'est-on alors pas en droit de s'attendre que le programme complète parfaitement son objectif, et par ce fait retrouve lui-même les règles de fonctionnement du corps humain? Cela prouve que le programme devant simuler un raisonnement inductif artificiel est erroné.

Juge: - Objection accordée, Mr. l'avocat de la défense, qu'avez-vous à répondre à cela?

Avocat IA: - J'argumenterai que cela ne prouve pas la validité des calcul du programme de mon client. Si l'on désirait prouver que l'erreur est uniquement due aux calcul de l'intelligence artificielle de mon client, il faudrait alors lui faire exécuter un test avec l'intégralité des données permettant d'induire ces règles rigoureusement exactes, c'est à dire lui faire exécuter intégralement une simulation de l'univers afin de s'assurer qu'aucun paramètre n'aurait été laissé de côté, quelle que soit la pertinence dont nous pensons que ce paramètre aie pu jouer dans le cas qui nous occupe aujourd'hui.

Juge: - Je demande la validation du contre-argument par notre expert.

Expert: - C'est en effet ce qu'en dit le mathématicien Pierre-Simon Laplace dans son *Essai philosophique sur les probabilités en 1814* : c'est l'approche déterministe. Même si cette approche est aujourd'hui controversée par ladite théorie du chaos, admettons que l'intelligence artificielle dont nous traitons aujourd'hui le cas soit capable d'une telle prouesse que de prévenir de manière infaillible l'avenir à partir des données complète de l'univers. Le temps nécessaire pour simuler l'évolution de l'état de santé de M. Michou selon tous les scénarios possible aurait dépassé alors de loin le temps que ce diabète ne fasse perdre la vue à ce pauvre homme. C'est un souci qu'avis déjà envisagé Alan Turing en 1950 et qui ne peut toujours pas être résolu même avec nos technologies actuelles. Nos méthodes de prédiction doivent alors se baser sur des théories émergentes, c'est-à-dire permettant de s'approcher au plus près d'une réalité observée, sans pouvoir garantir le risque zéro d'échec.
