# Pièce de Théâtre

## Thème(s)

Une IA (IDX DR) est assignée en justice pour erreur de diagnostique. Un patient a perdu la vue suite au non traitement de son cas.

### Problématiques

- L'IA peut-elle être tenue responsable?
- La performance de l'IA surpasse celle des humains

## Rôles

- Avocat IA
- Procureur
- Utilisateur
- Programmeur
- Organisme d'agrémentation médicale (AFD)

## Arguments

- C'est la faute du programmeur
  - Le programmeur n'a pas la main sur les résultats (Deep Learning)
- C'est la faute du fournisseur de données
- L'IA est agrémentée, c'est la faute de l'organisme
- La marge d'erreur était connue à l'avance
- La décision n'a pas été prise par l'IA
- L'erreur aurait pu être faite par un humain

## Structure

1. L'accusation est introduite par le procureur. Exposition des faits: M. Michou a perdu la vue suite au non traitement de son cas.
2. Un (ou des) expert(s) technique(s) présente l'IA mise en cause.
  a. Définition de l'IA
  b. Le type d'IA (machine learning, deep learning)
  c. Son apprentissage et agrémentation
3. Practicien / médecin / diagnosticien explique son choix (ou non) d'adopter l'IA
  - l'IA est agrémentée par un organisme d'autorité (FTA)
  - l'IA a montré des performances supérieures aux humains
4. L'expert précise que l'IA peut faire des erreurs
  - Le jeu de données peut-être insuffisant ( M. Michou était albinos, un cas sur 20 000, 4500 personnes en France )

## Conclusion

L'importance des processus d'apprentissage et du contrôle des résultats.
